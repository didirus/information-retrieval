{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "import math\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nr_documents = 5\n",
    "relevances_cats = ['N', 'R', 'HR']\n",
    "relevances_vals = [0,1,5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "STEP 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split_list(a_list):\n",
    "    half = len(a_list)/2\n",
    "    return [a_list[:half], a_list[half:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_combinations_list(relevances):  \n",
    "    combinations = []\n",
    "    for i in itertools.product(relevances, repeat = nr_documents*2):\n",
    "        i = list(i)\n",
    "        i = split_list(i)\n",
    "        combinations.append(i)\n",
    "    return combinations\n",
    "\n",
    "combinations_cats = get_combinations_list(relevances_cats)\n",
    "combinations_vals = get_combinations_list(relevances_vals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "STEP 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Precision\n",
    "\n",
    "Calculates precision at rank k with a list with 3 relevance levels (R, HR and N). 'Precision at rank k' though, asks for a binary classication problem, so HR and R is counted as relevant (1) and N as non-relevant(0).\n",
    "\n",
    "k must be 5 or smaller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def precision_at(k):\n",
    "    countTP = 0 # amount of true positives\n",
    "    countFP = 0 # amount of false positives\n",
    "    precisionList =[]\n",
    "    for j in combinations_cats:\n",
    "        kcounter = 0\n",
    "        for m in range(0, k):\n",
    "            l = j[0][m]\n",
    "            if l == 'R': countTP+=1\n",
    "            elif l == 'HR': countTP+=1\n",
    "            else : countFP+=1\n",
    "            precisionP = countTP/float(countTP+countFP)\n",
    "        countTP=0\n",
    "        countFP=0\n",
    "        for m in range(0,k):\n",
    "            l = j[1][m]\n",
    "            if l == 'R': countTP+=1\n",
    "            elif l == 'HR': countTP+=1\n",
    "            else : countFP+=1\n",
    "            precisionE = countTP / float(countTP + countFP)\n",
    "        precisions = [precisionP, precisionE]\n",
    "        precisionList.append(precisions)\n",
    "    return precisionList"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DCG\n",
    "\n",
    "k must be 5 or smaller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dcg_at(k):\n",
    "    EP_results = []\n",
    "    for relevances in combinations_vals:\n",
    "        rank_dcgs = []\n",
    "        for algorithm in relevances:\n",
    "            dcg = 0\n",
    "            for r in range(1,k+1):\n",
    "                dcg += ((2**algorithm[r-1])-1)/(math.log(1+r,2))\n",
    "            rank_dcgs.append(dcg)\n",
    "        EP_results.append(rank_dcgs)\n",
    "    return EP_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ERR\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def R(seq, g): # mapping from relevance grades g to probability of relevance           \n",
    "    return ((2**seq[g-1])-1)/float((2**max(relevances_vals)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def P(seq, r): # probability that user stops at position r\n",
    "    P = 1\n",
    "    for i in range(1,(r-1)+1):\n",
    "        P *= (1-R(seq, i)) * R(seq, r)\n",
    "    return P "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def err(): # a cascade based metric with x(r) = 1/r\n",
    "    ERR_results = []\n",
    "    for relevances in combinations_vals:\n",
    "        rank_err = []\n",
    "        for algorithm in relevances:\n",
    "            err = 0\n",
    "            for r in range(1, len(algorithm)+1):\n",
    "                err += (1/float(r))*P(algorithm, r)\n",
    "            rank_err.append(err)\n",
    "        ERR_results.append(rank_err)\n",
    "    return ERR_results "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "STEP 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_differences(results):\n",
    "    difference_measures=[]\n",
    "    for algo in results:\n",
    "        a = algo[0]\n",
    "        b = algo[1]\n",
    "        difference = b - a\n",
    "        if (difference > 0 ): difference_measures.append(difference)\n",
    "    return difference_measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "precision = precision_at(5)\n",
    "dcg = dcg_at(5)\n",
    "err = err()\n",
    "\n",
    "difference_measures = calculate_differences(precision)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "STEP 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def random_bit():\n",
    "    random.seed()\n",
    "    return random.getrandbits(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# generates a list with 10 random bits. 1 represents a click.\n",
    "\n",
    "def generate_random_clicks():\n",
    "    clicks = []\n",
    "    for i in range(nr_documents*2):\n",
    "        clicks.append(random_bit())\n",
    "    return clicks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Team-draft interleaving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def team_draft_interleaving(rankings, clicks):\n",
    "    random.seed()\n",
    "    credits = [0,0]\n",
    "    new_ranking = []\n",
    "    for i in range(nr_documents):\n",
    "        winner = random_bit()\n",
    "        \n",
    "        new_ranking.append(rankings[winner][i])\n",
    "        if clicks[len(new_ranking)-1] == 1:\n",
    "            credits[winner] += 1\n",
    "            \n",
    "        new_ranking.append(rankings[1-winner][i])\n",
    "        if clicks[len(new_ranking)-1] == 1:\n",
    "            credits[1-winner] += 1\n",
    "            \n",
    "    return new_ranking, credits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probabilistic interleaving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def probabilistic_interleaving():\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ranking P:  ['N', 'R', 'HR', 'R', 'HR']\n",
      "Ranking E:  ['R', 'R', 'HR', 'N', 'N']\n",
      "Team-Draft Interleaved ranking:  ['N', 'R', 'R', 'R', 'HR', 'HR', 'R', 'N', 'HR', 'N']\n",
      "P credits:  1\n",
      "E credits:  2\n"
     ]
    }
   ],
   "source": [
    "random.seed()\n",
    "rankings = [['N','R','HR','R','HR'], ['R','R','HR','N','N']]\n",
    "clicks = generate_random_clicks()\n",
    "\n",
    "### Team-draft interleaved ranking\n",
    "team_draft_interleaved_ranking, credits = team_draft_interleaving(rankings, clicks)\n",
    "print 'Ranking P: ', rankings[0]\n",
    "print 'Ranking E: ', rankings[1]\n",
    "print 'Team-Draft Interleaved ranking: ', team_draft_interleaved_ranking\n",
    "print 'P credits: ', credits[0]\n",
    "print 'E credits: ', credits[1]\n",
    "team_winning_algo = credits.index(max(credits))\n",
    "\n",
    "### Probabilistic interleaved ranking\n",
    "# prob_interleaved_ranking, credits = probabilistic_interleaving(rankings, clicks)\n",
    "# print 'Ranking P: ', rankings[0]\n",
    "# print 'Ranking E: ', rankings[1]\n",
    "# print 'Probabilistic Interleaved ranking: ', team_draft_interleaved_ranking\n",
    "# print 'P credits: ', credits[0]\n",
    "# print 'E credits: ', credits[1]\n",
    "# prob_winning_algo = credits.index(max(credits))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "STEP 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RCM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# required method (c)\n",
    "\n",
    "def is_clicked_RCM(nr_clicks, nr_docs):\n",
    "    P = nr_clicks / float(nr_docs)\n",
    "    flip = random.random()\n",
    "    return 1 if flip < P else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# required method (a)\n",
    "\n",
    "def get_parameter_RCM(filename):\n",
    "    nr_clicks = 0\n",
    "    nr_docs = 0\n",
    "    with open(filename) as f:\n",
    "        data = f.readlines()\n",
    "    for row in data:\n",
    "        if 'C' in row:\n",
    "            nr_clicks += 1\n",
    "        nr_docs += len(row) - 3\n",
    "    nr_docs -= nr_clicks\n",
    "    return nr_clicks, nr_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "simulated clicks:  [0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "# printing the simulated clicks\n",
    "\n",
    "sim_clicks_RCM = []   \n",
    "nr_clicks, nr_docs = get_parameter_RCM(\"training_data.txt\")\n",
    "for document in rankings[team_winning_algo]:\n",
    "    sim_clicks_RCM.append(is_clicked_RCM(nr_clicks, nr_docs))\n",
    "print 'simulated clicks: ', sim_clicks_RCM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other model X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# required method (c)\n",
    "def is_clicked_X():\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# required method (b)\n",
    "def predict_click_probabilities_X():\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# required method (a)\n",
    "def get_parameters_X():\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# printing the simulated clicks\n",
    "\n",
    "# sim_clicks_X = []   \n",
    "# get_parameter_X(\"training_data.txt\")\n",
    "# for document in rankings[team_winning_algo]:\n",
    "#     predict_click_probabilities_X()\n",
    "#     sim_clicks_X.append(is_clicked_RCM(nr_clicks, nr_docs))\n",
    "# print 'simulated clicks: ', sim_clicks_RCM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
