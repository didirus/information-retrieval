{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nr_documents = 5\n",
    "relevances_cats = ['N', 'R', 'HR']\n",
    "relevances_vals = [0,1,5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "STEP 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split_list(a_list):\n",
    "    half = len(a_list)/2\n",
    "    return [a_list[:half], a_list[half:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_combinations_list(relevances):  \n",
    "    combinations = []\n",
    "    for i in itertools.product(relevances, repeat = nr_documents*2):\n",
    "        i = list(i)\n",
    "        i = split_list(i)\n",
    "        combinations.append(i)\n",
    "    return combinations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "STEP 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Precision\n",
    "\n",
    "Calculates precision at rank k with a list with 3 relevance levels (R, HR and N). 'Precision at rank k' though, asks for a binary classication problem, so HR and R is counted as relevant (1) and N as non-relevant(0).\n",
    "\n",
    "k must be 5 or smaller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def precision_at(k, combinations_cats):\n",
    "    countTP = 0 # amount of true positives\n",
    "    countFP = 0 # amount of false positives\n",
    "    precisionList =[]\n",
    "    for j in combinations_cats:\n",
    "        kcounter = 0\n",
    "        for m in range(0, k):\n",
    "            l = j[0][m]\n",
    "            if l == 'R': countTP+=1\n",
    "            elif l == 'HR': countTP+=1\n",
    "            else : countFP+=1\n",
    "            precisionP = countTP/float(countTP+countFP)\n",
    "        countTP=0\n",
    "        countFP=0\n",
    "        for m in range(0,k):\n",
    "            l = j[1][m]\n",
    "            if l == 'R': countTP+=1\n",
    "            elif l == 'HR': countTP+=1\n",
    "            else : countFP+=1\n",
    "            precisionE = countTP / float(countTP + countFP)\n",
    "        precisions = [precisionP, precisionE]\n",
    "        precisionList.append(precisions)\n",
    "    return precisionList"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DCG\n",
    "\n",
    "k must be 5 or smaller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dcg_at(k, combinations_vals):\n",
    "    EP_results = []\n",
    "    for relevances in combinations_vals:\n",
    "        rank_dcgs = []\n",
    "        for algorithm in relevances:\n",
    "            dcg = 0\n",
    "            for r in range(1,k+1):\n",
    "                dcg += ((2**algorithm[r-1])-1)/(math.log(1+r,2))\n",
    "            rank_dcgs.append(dcg)\n",
    "        EP_results.append(rank_dcgs)\n",
    "    return EP_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ERR\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def R(seq, g): # mapping from relevance grades g to probability of relevance           \n",
    "    return ((2**seq[g-1])-1)/float((2**max(relevances_vals)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def P(seq, r): # probability that user stops at position r\n",
    "    P = 1\n",
    "    for i in range(1,(r-1)+1):\n",
    "        P *= (1-R(seq, i)) * R(seq, r)\n",
    "    return P "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def err(combinations_vals): # a cascade based metric with x(r) = 1/r\n",
    "    ERR_results = []\n",
    "    for relevances in combinations_vals:\n",
    "        rank_err = []\n",
    "        for algorithm in relevances:\n",
    "            err = 0\n",
    "            for r in range(1, len(algorithm)+1):\n",
    "                err += (1/float(r))*P(algorithm, r)\n",
    "            rank_err.append(err)\n",
    "        ERR_results.append(rank_err)\n",
    "    return ERR_results "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "STEP 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_differences(results):\n",
    "    difference_measures=[]\n",
    "    for algo in results:\n",
    "        a = algo[0]\n",
    "        b = algo[1]\n",
    "        difference = b - a\n",
    "        if (difference > 0 ): difference_measures.append(difference)\n",
    "    return difference_measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "combinations_cats = get_combinations_list(relevances_cats)\n",
    "combinations_vals = get_combinations_list(relevances_vals)\n",
    "\n",
    "precision = precision_at(5, combinations_cats)\n",
    "dcg = dcg_at(5, combinations_vals)\n",
    "err = err(combinations_vals)\n",
    "\n",
    "difference_measures = calculate_differences(precision)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "STEP 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def flip_coin():\n",
    "    random.seed()\n",
    "    return random.getrandbits(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# generates a list with 10 random bits. 1 represents a click.\n",
    "\n",
    "def generate_random_clicks():\n",
    "    clicks = []\n",
    "    for i in range(nr_documents*2):\n",
    "        clicks.append(flip_coin())\n",
    "    return clicks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Team-draft interleaving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def team_draft_interleaving(rankings, clicks):\n",
    "    random.seed()\n",
    "    credits = [0,0]\n",
    "    new_ranking = []\n",
    "    for i in range(nr_documents):\n",
    "        winner = flip_coin()\n",
    "        new_ranking.append(rankings[winner][i])\n",
    "        if clicks[len(new_ranking)-1] == 1:\n",
    "            credits[winner] += 1\n",
    "            \n",
    "        new_ranking.append(rankings[1-winner][i])\n",
    "        if clicks[len(new_ranking)-1] == 1:\n",
    "            credits[1-winner] += 1\n",
    "    \n",
    "    return credits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probabilistic interleaving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def init_softmaxes(rankings, tau):\n",
    "    denominator = 0\n",
    "    for i in range(1, (len(rankings[0])+1)):\n",
    "        denominator += 1 / float(i ** tau)\n",
    "    index = 1\n",
    "    softmax1 = []\n",
    "    softmax2 = []\n",
    "    for ranking in rankings[0]:\n",
    "        prob = (1/float(index**tau))/float(denominator)\n",
    "        softmax1.append(prob)\n",
    "        softmax2.append(prob)\n",
    "        index += 1\n",
    "    return softmax1, softmax2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def recalculate_softmax(softmax, pick):\n",
    "    softmax.remove(softmax[pick])\n",
    "    softmax[:] = [x/float(sum(softmax)) for x in softmax]\n",
    "    return softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def probabilistic_interleaving(rankings1, tau, clicks):\n",
    "    probrankings = copy.deepcopy(rankings1)\n",
    "    credits = [0,0]\n",
    "    conc_list = []\n",
    "    s1, s2 = init_softmaxes(probrankings, tau)\n",
    "    \n",
    "    while probrankings[0] or probrankings[1]:\n",
    "        \n",
    "        winner = flip_coin() # keep flipping until all lists are empty\n",
    "        \n",
    "        if winner == 0 and probrankings[0]:\n",
    "            \n",
    "            pick = np.random.choice(len(probrankings[0]), 1, p=s1)\n",
    "            conc_list.append(probrankings[winner][pick]) # add pick to the concatenated list\n",
    "            probrankings[winner].remove(probrankings[winner][pick]) # remove the pick from the document list\n",
    "            s1 = recalculate_softmax(s1, pick) # recalculate the softmax of that list to normalise\n",
    "            if clicks[len(conc_list)-1] == 1: credits[0] += 1\n",
    "                \n",
    "        elif winner == 1 and probrankings[1]:\n",
    "            \n",
    "            pick = np.random.choice(len(probrankings[1]), 1, p=s2)\n",
    "            conc_list.append(probrankings[winner][pick]) # add pick to the concatenated list\n",
    "            probrankings[winner].remove(probrankings[winner][pick]) # remove the pick from the document list\n",
    "            s2 = recalculate_softmax(s2, pick) # recalculate the softmax of that list to normalise\n",
    "            if (clicks[len(conc_list)-1] == 1): credits[1] += 1\n",
    "                \n",
    "    return credits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "STEP 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def process_data(filename):\n",
    "    data = []\n",
    "    with open(filename) as f:  \n",
    "        f = f.readlines()\n",
    "        for line in f:\n",
    "            data.append(line.split())\n",
    "    return data\n",
    "\n",
    "data = process_data(\"training_data.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rand():\n",
    "    return random.random()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# required method (c)\n",
    "def is_clicked(P):\n",
    "    result = 1 if rand() < P else 0\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RCM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# required method (b)\n",
    "def predict_click_probabilities_RCM(nr_clicks, nr_docs):\n",
    "    return nr_clicks / float(nr_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# required method (a)\n",
    "def get_parameter_RCM():\n",
    "    nr_clicks = 0\n",
    "    nr_docs = 0\n",
    "    for row in data:\n",
    "        if 'C' in row:\n",
    "            nr_clicks += 1\n",
    "        nr_docs += len(row) - 5 # 5 because first 5 elements is other information\n",
    "    nr_docs -= nr_clicks\n",
    "    return nr_clicks, nr_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final click_probability:  0.18\n"
     ]
    }
   ],
   "source": [
    "nr_clicks, nr_docs = get_parameter_RCM()\n",
    "click_probability_RCM = predict_click_probabilities_RCM(nr_clicks, nr_docs)\n",
    "print 'final click_probability: ', round(click_probability_RCM,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# printing the simulated clicks\n",
    "def get_clicks_RCM(nr_docs):\n",
    "    sim_clicks_RCM = []   \n",
    "    \n",
    "    \n",
    "    for document in range(nr_docs):\n",
    "        sim_clicks_RCM.append(is_clicked(click_probability_RCM))\n",
    "    return sim_clicks_RCM\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Position-based model PBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_click_probabilities_PBM(a, g):\n",
    "    click_probabilities = []\n",
    "    for i in range(len(a)):\n",
    "        P = a[i] * g[i]\n",
    "        click_probabilities.append(P)\n",
    "    return click_probabilities\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def new_gammas(g, a, queries):\n",
    "    all_query_gammas = [0] * 50 \n",
    "    for values in queries.values(): #[[docid, boolean],[...,...]] \n",
    "        query_gammas = g[:] # [0.5, 0.5, ...]\n",
    "        index = 0\n",
    "        for doc in values: # [docid, boolean]  \n",
    "            clicked = doc[1] # boolean\n",
    "            gamma = clicked + ((1-clicked)*(((1-a[index])*query_gammas[index])/(1-query_gammas[index]*a[index])))\n",
    "            query_gammas[index] = gamma\n",
    "            index +=1   \n",
    "        for i in range(len(query_gammas)):\n",
    "            all_query_gammas[i] += query_gammas[i]\n",
    "    \n",
    "    for i in range(len(all_query_gammas)):\n",
    "        all_query_gammas[i] /= len(queries)\n",
    "        \n",
    "    return all_query_gammas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_click_results(session):\n",
    "    query_results = {}\n",
    "    last_query = 0\n",
    "    for row in session:\n",
    "        # query action\n",
    "        if 'Q' in row: \n",
    "            last_query = row[3]\n",
    "            retrieved_docs = row[5:]\n",
    "            for docid in range(len((retrieved_docs))):\n",
    "                retrieved_docs[docid] = [retrieved_docs[docid], 0]\n",
    "            if row[3] not in query_results:     \n",
    "                query_results[row[3]] = retrieved_docs\n",
    "            else:\n",
    "                for i in range(len(retrieved_docs)):\n",
    "                    exists = False\n",
    "                    for document in query_results[row[3]]:\n",
    "                        if retrieved_docs[i][0] in document:\n",
    "                            exists = True\n",
    "                            break\n",
    "                    if not exists:\n",
    "                        query_results[row[3]] += [retrieved_docs[i]]\n",
    "                        \n",
    "        # click action\n",
    "        else:\n",
    "            found = False\n",
    "            while not found:\n",
    "                # check if its in the last query (most likely the correct query page)\n",
    "                for values in query_results[last_query]:\n",
    "                    if row[3] == values[0]:\n",
    "                        values[1] = 1\n",
    "                        found = True\n",
    "                        \n",
    "                # otherwise, check in other query pages\n",
    "                for queries in query_results.values():\n",
    "                    for values in queries:\n",
    "                        \n",
    "                        if row[3] == values[0]:\n",
    "                            values[1] = 1\n",
    "                            found = True\n",
    "                            \n",
    "    return query_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# required method (a)\n",
    "def get_parameters_PBM(data_slice):\n",
    "    alphas = [0.90] * 50 #list(np.arange(0.9,0.8,-0.001))\n",
    "    gammas = [0.5] * 50\n",
    "    learned_gammas = [0] * 50\n",
    "    \n",
    "    # get examination probabilities\n",
    "    sessions = set(map(lambda x:x[0], data_slice))\n",
    "    sessions_data = [[y for y in data_slice if y[0]==x] for x in sessions]\n",
    "    session_nr = 1\n",
    "    for session in sessions_data:\n",
    "        session_nr += 1\n",
    "        query_results = get_click_results(session)\n",
    "        session_gammas = new_gammas(gammas, alphas, query_results)\n",
    "        for i in range(len(session_gammas)):\n",
    "            learned_gammas[i] += session_gammas[i]\n",
    "    for i in range(len(learned_gammas)):\n",
    "        learned_gammas[i] /= len(sessions_data)\n",
    "        learned_gammas[i] = learned_gammas[i]\n",
    "    return alphas[:10], learned_gammas[:10]\n",
    "    \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "final click probabilities PBM: \n",
      "\n",
      "0.56 0.26 0.21 0.18 0.16 0.15 0.14 0.13 0.13 0.13\n"
     ]
    }
   ],
   "source": [
    "data_slice = data[0:20000]\n",
    "alphas, gammas = get_parameters_PBM(data_slice)\n",
    "click_probabilities_PBM = predict_click_probabilities_PBM(alphas[:10], gammas[:10])\n",
    "\n",
    "print '\\nfinal click probabilities PBM: \\n'#, learned_gammas\n",
    "for i in click_probabilities_PBM:\n",
    "    print round(i,2),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# printing the simulated clicks\n",
    "def get_clicks_PBM(nr_docs):\n",
    "    sim_clicks_PBM = []      \n",
    "    for document_index in range(nr_docs):\n",
    "        sim_clicks_PBM.append(is_clicked(click_probabilities_PBM[document_index]))\n",
    "#     print 'simulated clicks PBM: ', sim_clicks_PBM\n",
    "    return sim_clicks_PBM\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "STEP 6 \n",
    "\n",
    "Experiments.\n",
    "\n",
    "\n",
    "This method runs N experiments with a list of categorical rankings E and P with categories (HR/R/N).\n",
    "It takes one of the rankings and runs both a team_draft and probabilistic interleave with different random click values, but with the same ranking.\n",
    "\n",
    "\n",
    "We should think of what it means to use different ranking combinations or the same click values for each simulation.\n",
    "\n",
    "\n",
    "It prints out the E proportion for both the team-draft and the probabilistic interleave.\n",
    "\n",
    "\n",
    "We should make a measure for which we can compare results between on- and offline evaluation, between the 2 interleaves and the different click models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pair:  1 / 59049\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/diederusticus/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:22: VisibleDeprecationWarning: converting an array with ndim > 0 to an index will result in an error in the future\n",
      "/Users/diederusticus/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:23: VisibleDeprecationWarning: converting an array with ndim > 0 to an index will result in an error in the future\n",
      "/Users/diederusticus/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:2: VisibleDeprecationWarning: converting an array with ndim > 0 to an index will result in an error in the future\n",
      "  from ipykernel import kernelapp as app\n",
      "/Users/diederusticus/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:14: VisibleDeprecationWarning: converting an array with ndim > 0 to an index will result in an error in the future\n",
      "/Users/diederusticus/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:15: VisibleDeprecationWarning: converting an array with ndim > 0 to an index will result in an error in the future\n"
     ]
    }
   ],
   "source": [
    "def interleaving_experiment(ranking_pairs, N):\n",
    "    wins_P_E = [0,0]\n",
    "    ties = 0\n",
    "    nr_pair = 0\n",
    "    pairs_E_outperforms_P = []\n",
    "    for pair in ranking_pairs:\n",
    "        \n",
    "        # printing some intermediair results\n",
    "        nr_pair += 1\n",
    "        if nr_pair == 1:\n",
    "            print 'pair: ', nr_pair, '/', len(ranking_pairs)\n",
    "        if nr_pair % 500 == 0:\n",
    "            print 'pair: ', nr_pair, '/', len(ranking_pairs),\n",
    "#         if nr_pair % 3000 == 0:\n",
    "            total_games = ties + sum(wins_P_E)\n",
    "            p = wins_P_E[1]/float(total_games)\n",
    "            print ' P wins:', wins_P_E[0], 'E wins:', wins_P_E[1], 'Ties:', ties, 'Total nr games:', total_games, 'P:', p\n",
    "            \n",
    "        # executing the N simulations    \n",
    "        for i in range(N):\n",
    "            \n",
    "            # generating 2 sets of clicks of the models\n",
    "            PBM_clicks = get_clicks_PBM(10) # 10 = nr of clickdecisions\n",
    "            RCM_clicks = get_clicks_RCM(10)\n",
    "            click_models = [PBM_clicks, RCM_clicks]\n",
    "            \n",
    "            # per click model:\n",
    "            for clicks in click_models:\n",
    "                \n",
    "                # perform both interleaf algorithms:\n",
    "                interleaf_credits = [team_draft_interleaving(pair, clicks), probabilistic_interleaving(pair, 3, clicks)]\n",
    "                \n",
    "                # and for both interleaf credit results, keep score of P and E and also a tie-count\n",
    "                for credits in interleaf_credits:\n",
    "                    if credits[0] != credits[1]: # if not a tie\n",
    "                        wins_P_E[credits.index(max(credits))] += 1\n",
    "                        if credits.index(max(credits)) == 1 and pair not in pairs_E_outperforms_P:\n",
    "                            pairs_E_outperforms_P.append(pair)\n",
    "                    else:\n",
    "                        ties += 1\n",
    "                        \n",
    "    # printing the results\n",
    "    total_games = ties + sum(wins_P_E)\n",
    "    print 'win counts: ', wins_P_E\n",
    "    print 'ties: ', ties\n",
    "    print 'total_games: ', total_games\n",
    "    print 'proportion p of wins of E: ', wins_P_E[1]/float(total_games)\n",
    "    return pairs_E_outperforms_P, wins_P_E[1]/float(total_games)\n",
    "    \n",
    "combinations_cats = get_combinations_list(relevances_cats)\n",
    "pairs_E_outperforms_P, p = interleaving_experiment(combinations_cats, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
